{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from razdel import tokenize\n",
    "import pandas as pd\n",
    "\n",
    "special_regex = re.compile('\\d{2}.\\d{2}.\\d{2}')\n",
    "emoj = re.compile('['\n",
    "                  u'\\U0001F600-\\U0001F64F'\n",
    "                  u'\\U0001F300-\\U0001F5FF'\n",
    "                  u'\\U0001F680-\\U0001F6FF'\n",
    "                  u'\\U0001F1E0-\\U0001F1FF'\n",
    "                  u'\\U00002500-\\U00002BEF'\n",
    "                  u'\\U00002702-\\U000027B0'\n",
    "                  u'\\U000024C2-\\U0001F251'\n",
    "                  u'\\U0001f926-\\U0001f937'\n",
    "                  u'\\U00010000-\\U0010ffff'\n",
    "                  u'\\u2640-\\u2642'\n",
    "                  u'\\u2600-\\u2B55'\n",
    "                  u'\\u200d'\n",
    "                  u'\\u23cf'\n",
    "                  u'\\u23e9'\n",
    "                  u'\\u231a'\n",
    "                  u'\\ufe0f'\n",
    "                  u'\\u3030'\n",
    "                  ']', re.UNICODE)\n",
    "with open('../DATA/less_semantic_words.txt', 'r', encoding='utf-8') as f:\n",
    "    stop_words = pd.Series(f.read().split('\\n')).unique()\n",
    "\n",
    "\n",
    "main_url = 'https://leader-id.ru/'\n",
    "user_suburl = 'users/'\n",
    "test_user_id = '2234799' \n",
    "\n",
    "headers_for_users = [\n",
    "    'Интересы',\n",
    "    'Активность',\n",
    "    # 'Проекты',\n",
    "    'Команды'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textNormalization(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = ' '.join(list(filter(lambda a: len(a), text.split(' '))))\n",
    "    return text\n",
    "\n",
    "def clear_from_stopwords(text, sw):\n",
    "    text = text\n",
    "    tokens = list(tokenize(text))\n",
    "    t = []\n",
    "    for i in tokens:\n",
    "        if len(i.text) > 2:\n",
    "            if i.text not in sw:\n",
    "                t.append(i.text)\n",
    "\n",
    "    return ' '.join(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = requests.get(main_url + user_suburl + test_user_id).content\n",
    "soup = BeautifulSoup(ms, 'html.parser').find(class_='page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(block):\n",
    "    if textNormalization(block.h3.text) == 'Интересы':\n",
    "        return set(filter(len, [clear_from_stopwords(textNormalization(i.text), stop_words).lower() for i in  block.find_all('span')]))\n",
    "    if textNormalization(block.h3.text) == 'Команды':\n",
    "        return {clear_from_stopwords(textNormalization(j.text), sw=stop_words).lower(): clear_from_stopwords(textNormalization(i.text), sw=stop_words).lower() for i, j in zip(block.find_all('h4'), block.find_all('p'))}\n",
    "    if textNormalization(block.h3.text) == 'Активность':\n",
    "        return {clear_from_stopwords(textNormalization(i.text), sw=stop_words).lower(): i['href'] for i in block.find_all('a')}\n",
    "        # return {textNormalization(j.text): textNormalization(i.text) for i, j in zip(block.find_all('h4'), block.find_all('p'))}\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'торжественное открытие ит-хаба окружного хакатона цифров ...': '/events/468237', 'защита учебной практики студентами кафедры прикладная ...': '/events/440288', 'итоговая защита проектов пои 2023': '/events/421421', 'хакатон разработке it-решения партнер омскстат': '/events/423140', '122-й математический it-субботник': '/events/376962', 'введение nlp': '/events/402031', 'экспертиза проектов выполняемых рамках выпускных квали ...': '/events/407353', 'частые практики дизайн-мышлению': '/events/402028'}\n",
      "{'большие данные', 'квантовые технологии', 'образование', 'edunet', 'energynet', '2234799', 'профессиональное', 'игропрактики', 'управление проектами', 'мероприятие технологической команды', 'птк', 'журналистика', 'беспроводная связь вещей', 'машинное обучение анализ данных', 'foodnet', 'autonet', 'gamenet', 'дополнительное', 'личное профессиональное развитие', 'technet', 'искусственный интеллект машинное обучение', 'михаил александрович смирнов', 'программирование', 'neuronet', 'wearnet', 'рационализаторство', 'healthnet', 'дети'}\n",
      "{'команда интенсива пои 2023 треку формирование цифрового профиля обучающегося цифровому следу': 'формирование цифрового профиля обучающегося цифровому следу', 'формирование цифрового профиля обучающегося цифровому следу': 'формирование цифрового профиля обучающегося цифровому следу'}\n"
     ]
    }
   ],
   "source": [
    "for i in set([i for i in soup.find_all('h3') if textNormalization(i.text) in headers_for_users]):\n",
    "    print(processing(i.find_parents()[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LofDT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
